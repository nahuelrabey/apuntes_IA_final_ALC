# Demostraci√≥n: Independencia Lineal de Autovectores con Autovalores Distintos

## Interpretaci√≥n del Enunciado

> Demostrar formalmente el lema matricial que establece que si una matriz cuadrada $A \in \mathbb{R}^{n \times n}$ posee autovalores estrictamente distintos entre s√≠ ($\lambda_i \neq \lambda_j$), entonces sus autovectores correspondientes $\{v_1, v_2, \dots, v_n\}$ son un conjunto de vectores **linealmente independientes**.

La importancia vital de este teorema radica en que es la base misma de la **diagonalizaci√≥n**. Si una matriz de orden $n$ logra disponer de $n$ autovectores independientes, √©stos formar√°n una Base para todo el hiperplano $\mathbb{R}^n$, posibilitando armar una matriz de permutaci√≥n $P$ invertible que desemboque en un c√°lculo como $A = P D P^{-1}$.

Demostraremos deductivamente esta verdad apelando al Principio de Inducci√≥n Fuerte sobre el n√∫mero de autovectores $k$ evaluados simult√°neamente.

## Soluci√≥n Anal√≠tica (Demostraci√≥n por Contradicci√≥n)

La siguiente demostraci√≥n est√° fundamentada en el libro *"√Ålgebra Lineal y sus Aplicaciones"* (David C. Lay), operando mediante la t√©cnica de contradicci√≥n sobre el conjunto dependiente m√°s peque√±o posible.

**PRUEBA.** Supongamos, buscando una contradicci√≥n, que el conjunto de autovectores $\{v_1, \dots, v_r\}$ es **linealmente dependiente**.

Como cada uno de los vectores propios $v_1$ es no nulo por definici√≥n ($v_i \neq 0$), sabemos por teoremas previos de dependencia lineal que al menos uno de los vectores en el conjunto debe ser reducible a una combinaci√≥n lineal de sus predecesores.

Sea entonces $p$ el √≠ndice m√°s peque√±o ("*least index*") tal que el vector $v_{p+1}$ es una combinaci√≥n lineal de los vectores que lo preceden (los cuales, por la misma definici√≥n del subconjunto m√≠nimo, asumimos linealmente independientes). Entonces, existir√°n obligatoriamente escalares $c_1, \dots, c_p$ tales que:

$$
(Eq. 5) \quad c_1 v_1 + \dots + c_p v_p = v_{p+1}
$$

Si multiplicamos ambos lados de la ecuaci√≥n $(Eq. 5)$ por la matriz original $A$, y utilizamos el hecho fundacional de que $A v_k = \lambda_k v_k$ para cada √≠ndice $k$, obtenemos:

$$
c_1 A v_1 + \dots + c_p A v_p = A v_{p+1}
$$

$$
(Eq. 6) \quad c_1 \lambda_1 v_1 + \dots + c_p \lambda_p v_p = \lambda_{p+1} v_{p+1}
$$

En paralelo, podemos tomar nuestra $(Eq. 5)$ inmaculada y multiplicarla directamente en ambos lados por el autovalor extra√≠do $\lambda_{p+1}$, y luego, **restar ese resultado a nuestra nueva ecuaci√≥n matricial $(Eq. 6)$**. Esto nos deja:

$$
(Eq. 7) \quad c_1 (\lambda_1 - \lambda_{p+1}) v_1 + \dots + c_p (\lambda_p - \lambda_{p+1}) v_p = \mathbf{0}
$$

Dado que el subconjunto anterior $\{v_1, \dots, v_p\}$ era asertivamente nuestro n√∫cleo linealmente independiente, estamos forzados a concluir que todos los "pesos macros" (o coeficientes) en la ecuaci√≥n $(Eq. 7)$ deben ser rigurosamente un cero absoluto.

Sin embargo, sabemos imperativamente que ninguno de los factores compuestos por la diferencia $(\lambda_i - \lambda_{p+1})$ son cero, **debido a que la premisa fundamental estipula que todos los valores propios son estrictamente distintos**.

Por mera inferencia y despeje matem√°tico, la culpa matem√°tica de anular la ecuaci√≥n recae √≠ntegramente de que:

$$
c_i = 0 \quad \text{para } i = 1, \dots, p
$$

¬°Pero si regresamos e insertamos todos estos ceros absolutos en nuestra primera e inmaculada aserci√≥n $(Eq. 5)$, la matem√°tica dictamina catastr√≥ficamente que $v_{p+1} = \mathbf{0}$!

Esto es un exabrupto y completamente **imposible**, ya que viola la doctrina de que los vectores propios nunca pueden consistir en el vector nulo. Por ende, como hemos chocado de frente con una contradicci√≥n irrompible, nuestra suposici√≥n primigenia debe ser falsa.

El racimo $\{v_1, \dots, v_r\}$ jam√°s pudo haber sido linealmente dependiente desde un comienzo y, por tanto, **debe ser linealmente independiente**. ‚àé

---

## Verificaci√≥n Emp√≠rica Computacional

La veracidad de este postulado inductivo abstracto fue sometida a estr√©s sist√©mico por medio del validador aleatorio programado en Python, corroborando por flotantes y en repetidos ciclos la premisa sin contradicciones.

```python
--8<-- "demostraciones/autovalores_distintos.py"
```

---

## Bibliograf√≠a y Recursos Educativos

Para comprender mejor los pasos algebraicos explicados en la demostraci√≥n por inducci√≥n de este documento, a continuaci√≥n se listan varios recursos externos que recorren y validan la misma secuencia l√≥gica:

### üìñ Libros de Texto y Art√≠culos

- **Libro: √Ålgebra Lineal y sus Aplicaciones (David C. Lay)**. *Cap√≠tulo 5: Valores Propios y Vectores Propios*. El autor introduce formalmente el "Teorema 2" de este cap√≠tulo (pag. 273 en la 4ta edici√≥n), el cual versa: *Si $v_1, ..., v_r$ son vectores propios que corresponden a valores propios distintos $\lambda_1, ..., \lambda_r$ de una matriz $n \times n$ $A$, entonces el conjunto $\{v_1, ..., v_r\}$ es linealmente independiente.* La demostraci√≥n en el libro avanza por **contradicci√≥n** y utiliza exactamente las mismas restas anal√≠ticas presentadas en este apunte para llevar los c-escalares a cero.
- **Libro: Linear Algebra and Its Applications (Gilbert Strang)**. *Cap√≠tulo 6*. Strang tambi√©n formaliza que si poseemos $n$ *eigenvalues* distintos en la matriz $A$, ineludiblemente contaremos con $n$ *eigenvectors* independientes, asegurando la propiedad de que toda matriz sim√©trica con espectro √∫nico puede diagonalizarse como $S \Lambda S^{-1}$.

### üá™üá∏ Videos en Espa√±ol

- **[√Ålgebra Lineal - Autovectores. Propiedades de independencia lineal](https://www.youtube.com/watch?v=KmjpJtXbk90)** (Prof. Jes√∫s Soto, UCAM): El video aborda la prueba de una manera sumamente clara y pausada. Muestra precisamente la misma construcci√≥n de la ecuaci√≥n original $\text{Eq. 1}$, la aplicaci√≥n de la matriz $A$, y la multiplicaci√≥n por el $n$-√©simo autovalor para forzar la eliminaci√≥n en la resta.
- **[Autovalores y Diagonalizaci√≥n - Multiplicidad de autovectores](https://www.youtube.com/watch?v=JalJlpAYZvw)** (OpenFING): Clase de facultad universitaria donde se demuestra rigurosamente el teorema iterando el mismo concepto matem√°tico de asumir un subconjunto de multiplicidad $k$ L.I. y verificar el eslab√≥n $k+1$.

### üá∫üá∏ Videos en Ingl√©s

- **[Linear Independence of Eigenvectors (Proof by Induction)](https://www.youtube.com/watch?v=Fljli8GcfEs)** (Dr. Peyam): Excelente y pedag√≥gica explicaci√≥n que arma el Caso Base ($k=1$) logrando que $c_1 = 0$, para luego saltar a lo que denomina "una inducci√≥n muy hermosa" documentando exactamente el mismo razonamiento y notaci√≥n algebraica planteado en este apunte.
