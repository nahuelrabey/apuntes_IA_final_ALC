# Lecciones y Conclusiones Aprendidas

A través de las validaciones teórico-prácticas elaboradas en nuestra metodología de estudio, derivamos las siguientes conclusiones analíticas.

## Examen 21 de jul de 2025

### Ejercicio 1 - SVD
- **Acotación de Errores con Valores Singulares:** Demostramos teóricamente y empíricamente cómo las aproximaciones de rango inferior truncando la SVD acotan su error máximo en norma Euclídea por el valor del siguiente valor singular omitido ($\sigma_2$). Esto reafirma la contundente utilidad de SVD en compresión matemática de datos con pérdidas rígidamente controladas.
- **Convergencia Práctica del Método de la Potencia:** Demostramos mediante álgebra cómo iterar estocásticamente $x^{(k+1)} = \frac{Bx^{(k)}}{||Bx^{(k)}||}$ alinea rápidamente el vector a la componente principal dominante purgando a las demás bases por diferencias en el ratio de sus autovalores $\left(\frac{\lambda_2}{\lambda_1}\right)^k \to 0$. Esto nos permitió desarrollar una rutina de aproximación de rango 1 que iguala analíticamente en su resultado a las librerías industriales complejas.

## Examen 24 de feb de 2025

### Ejercicio 2 - Semejanza y SVD
- **Uso de Invarianzas y Transformaciones Ortogonales:** En matemáticas (como ocurre con la SVD), aplicar operaciones "isométricas" o transformaciones ortogonales (como fue multiplicar por una matriz de permutación aleatoria computacionalmente, $P$) resulta invariante para las magnitudes nucleares (como el espectro singular). 
- **La Utilidad de la Permutación Aleatoria Computada:** A la hora de verificar propiedades sobre operadores donde "El orden de las filas no altera el resultado estructural", utilizar una matriz de permutación estocástica (`P = I[np.random.permutation(n), :]`) sobre el código es un factor de prueba estupendo. Si la propiedad estadística persiste (ejemplo, la invariabilidad de `np.linalg.svd`) probamos empíricamente la independencia matemática del operador evaluado y confirmamos el modelo numérico.
- **Estabilidad de las Normas (Norma-2):** El script nos demostró cómo este tipo de transformaciones no introducen ruido algorítmico al "estiramiento" máximo de la matriz (la Norma 2) ni a su número de condición. Computarizar $\|PA\|_2$ arrojó consistentemente el mismo resultado de norma debido a que los ortogonales preservan las longitudes vectoriales subyacentes, validando lo deducido con lápiz y papel.

### Ejercicio 3 - Métodos Iterativos
- **Del Radio Espectral al Código Empírico:** Observamos cómo la teoría matricial predice exáctamente el comportamiento iterativo del `while-loop`. A diferencia del algebra matricial analítica, el cálculo numérico involucra medir tiempos (tasas) de procesamiento. Si el análisis formal sostiene que la tasa de convergencia asintótica de una técnica es el doble de la que presenta otra ($\rho(T_{GS}) = \rho(T_J)^2$), computarizar un simple contador de los pasos que toma domar un residuo a una tolerancia límite dada (como $1e^{-10}$) nos ofrecerá una corroboración tajante donde comprobaremos cómo, en efecto, el loop computará la mitad de las iteraciones.
- **Micro-optimizaciones Matemáticas en el Bloque RAM:** La forma iterativa de Gauss-Seidel demuestra conceptualmente un principio de las ciencias computacionales aplicado tempranamente a los algoritmos continuos. La "actualización inmediata" o *in-place updating* (donde $x_2^{(k+1)}$ se reutiliza inmediatamente sin demorarnos a la iteración $(k+1)$ en el bloque en memoria) ahorra recursos del caché y virtualmente duplica la velocidad del procesamiento comparado con Jacobi, que exige retener en memoria secundaria una foto en frío del vector íntegro $X^{(k)}$ del pasado.

### Ejercicio 4 - Mínimos Cuadrados
- **Transformación de Hipóstasis Exponenciales:** Estudiamos cómo la vasta mayoría de las regresiones empíricas no-lineales en la naturaleza se reducen, algorítmicamente, a simples regresiones lineales ordinarias que las computadoras (como `numpy.linalg`) pueden resolver al instante si aplicamos isomorfismos biyectivos. Bajar el exponente $z = a \cdot y^b$ vía logaritmos naturales independiza por la fuerza una función intratable y nos la otorga en bandeja de plata como modelo paramétrico $\beta_0 + \beta_1 X$ compatible con la rígida Ecuación Normal de M.C.O.
- **Validación del Determinante Experimental:** En la programación probabilística de datos es usual arrojarle a la máquina miles de registros esperando que encuentre promedios ponderados. Este ejercicio resalta el valor semántico de la Independencia Lineal como pilar subyacente de la Computabilidad. Diseñar un array de control minúsculo adrede (de apenas 3 puntos de prueba) y observar que es materialmente el número mínimo insalvable para que el algoritmo arroje un `LinAlgError` si no reparamos en la dependencia, permite trazar una raya visible entre un algoritmo "que funciona de casualidad" y un entendimiento total de las fronteras matemáticas de las librerías estadísticas subyacentes.
