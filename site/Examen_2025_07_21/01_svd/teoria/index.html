
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="Nahuel">
      
      
      
        <link rel="prev" href="../../../lecciones_aprendidas/">
      
      
        <link rel="next" href="../../02_diagonalizacion/teoria/">
      
      
        
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.2">
    
    
      
        <title>01. Descomposici贸n SVD - Finales lgebra Lineal Computacional</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="cyan">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#solucion-del-ejercicio-1-examen-21-de-julio-de-2025-svd" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Finales lgebra Lineal Computacional" class="md-header__button md-logo" aria-label="Finales lgebra Lineal Computacional" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Finales lgebra Lineal Computacional
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              01. Descomposici贸n SVD
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="cyan"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
  
    
  
  Introducci贸n

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../lecciones_aprendidas/" class="md-tabs__link">
        
  
  
    
  
  Lecciones Aprendidas

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="./" class="md-tabs__link">
          
  
  
  Examen 21 de jul de 2025

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../Examen_2025_02_24/01_semejanza_matrices/teoria/" class="md-tabs__link">
          
  
  
  Examen 24 de feb de 2025

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../Examen_2025_08_07/01_proyector/teoria/" class="md-tabs__link">
          
  
  
  Examen 07 de ago de 2025

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../demostraciones/01_metodo_potencia/" class="md-tabs__link">
          
  
  
  Demostraciones

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Finales lgebra Lineal Computacional" class="md-nav__button md-logo" aria-label="Finales lgebra Lineal Computacional" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Finales lgebra Lineal Computacional
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Introducci贸n
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../lecciones_aprendidas/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Lecciones Aprendidas
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Examen 21 de jul de 2025
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Examen 21 de jul de 2025
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    01. Descomposici贸n SVD
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    01. Descomposici贸n SVD
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#interpretacion-del-enunciado" class="md-nav__link">
    <span class="md-ellipsis">
      
        Interpretaci贸n del enunciado
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#solucion-inciso-a" class="md-nav__link">
    <span class="md-ellipsis">
      
        Soluci贸n Inciso A
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#solucion-inciso-b" class="md-nav__link">
    <span class="md-ellipsis">
      
        Soluci贸n Inciso B
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#solucion-inciso-c-rutina-en-python" class="md-nav__link">
    <span class="md-ellipsis">
      
        Soluci贸n Inciso C: Rutina en Python
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../02_diagonalizacion/teoria/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    02. Diagonalizaci贸n
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../03_matrices_ortogonales/teoria/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    03. Matrices Ortogonales
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../04_cuadrados_minimos/teoria/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    04. Cuadrados M铆nimos
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../05_cauchy_schwartz/teoria/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    05. Cauchy-Schwartz
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Examen 24 de feb de 2025
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Examen 24 de feb de 2025
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Examen_2025_02_24/01_semejanza_matrices/teoria/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    01. Semejanza de Matrices
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Examen_2025_02_24/02_descomposicion_svd/teoria/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    02. Descomposici贸n SVD
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Examen_2025_02_24/03_metodos_iterativos/teoria/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    03. M茅todos Iterativos
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Examen_2025_02_24/04_minimos_cuadrados/teoria/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    04. M铆nimos Cuadrados
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Examen 07 de ago de 2025
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Examen 07 de ago de 2025
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Examen_2025_08_07/01_proyector/teoria/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    01. Proyectores y Subespacios
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Examen_2025_08_07/02_markov/teoria/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    02. Cadenas de Markov
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Examen_2025_08_07/03_cuadrados_minimos/teoria/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    03. Cuadrados M铆nimos Revisitado
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Examen_2025_08_07/04_numero_condicion/teoria/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    04. Condicionamiento y Estabilidad
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../Examen_2025_08_07/05_descomposicion_lu/teoria/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    05. Descomposici贸n LU
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Demostraciones
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Demostraciones
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../demostraciones/01_metodo_potencia/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    01. M茅todo de la Potencia
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../demostraciones/02_autovalores_distintos/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    02. Independencia de Autovectores
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../demostraciones/03_determinante_producto/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    03. Regla del Determinante
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../demostraciones/04_teorema_espectral/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    04. Teorema Espectral
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#interpretacion-del-enunciado" class="md-nav__link">
    <span class="md-ellipsis">
      
        Interpretaci贸n del enunciado
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#solucion-inciso-a" class="md-nav__link">
    <span class="md-ellipsis">
      
        Soluci贸n Inciso A
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#solucion-inciso-b" class="md-nav__link">
    <span class="md-ellipsis">
      
        Soluci贸n Inciso B
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#solucion-inciso-c-rutina-en-python" class="md-nav__link">
    <span class="md-ellipsis">
      
        Soluci贸n Inciso C: Rutina en Python
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="solucion-del-ejercicio-1-examen-21-de-julio-de-2025-svd">Soluci贸n del Ejercicio 1 (Examen 21 de julio de 2025 - SVD)</h1>
<blockquote>
<p><strong>Ejercicio 1.</strong> Sea <span class="arithmatex">\(A\)</span> una matriz con coeficientes reales de <span class="arithmatex">\(n \times 2\)</span>. Sean <span class="arithmatex">\(U\)</span>, <span class="arithmatex">\(\Sigma\)</span> y <span class="arithmatex">\(V\)</span> las matrices que dan su descomposici贸n SVD, con <span class="arithmatex">\(u_i\)</span> la columna <span class="arithmatex">\(i\)</span>-茅sima de <span class="arithmatex">\(U\)</span>, <span class="arithmatex">\(\Sigma_{ii} = \sigma_i\)</span> (con <span class="arithmatex">\(\sigma_i \neq \sigma_j\)</span> si <span class="arithmatex">\(i \neq j\)</span>), y <span class="arithmatex">\(v_i\)</span> la columna <span class="arithmatex">\(i\)</span>-茅sima de <span class="arithmatex">\(V\)</span>. Sea <span class="arithmatex">\(\tilde{A} = \sigma_1 u_1 v_1^t\)</span> una aproximaci贸n de rango 1 de <span class="arithmatex">\(A\)</span>.</p>
<p>a) Si <span class="arithmatex">\(x \in \mathbb{R}^2\)</span> es un vector perteneciente al c铆rculo unitario, mostrar que el error cometido al calcular <span class="arithmatex">\(Ax\)</span> como <span class="arithmatex">\(\tilde{A}x\)</span> est谩 acotado por <span class="arithmatex">\(\sigma_2\)</span>.</p>
<p>b) Sea <span class="arithmatex">\(B = A^tA\)</span> y <span class="arithmatex">\(x \in \mathbb{R}^2\)</span> elegido al azar. Mostrar que el siguiente algoritmo converge al vector <span class="arithmatex">\(v_1\)</span> cuando <span class="arithmatex">\(N \to \infty\)</span>:</p>
<ul>
<li>
<p>Para <span class="arithmatex">\(k \in 1, \dots, N\)</span>:</p>
</li>
<li>
<p><span class="arithmatex">\(x = Bx\)</span></p>
</li>
<li>
<p><span class="arithmatex">\(x = x / ||x||\)</span></p>
</li>
</ul>
<p>c) Escriba una rutina que calcule la mejor aproximaci贸n de rango 1 de una matriz real de <span class="arithmatex">\(n \times 2\)</span> en el sentido de la norma 2. Toda funci贸n que involucre operaciones m谩s complejas que el producto matricial debe ser definida expl铆citamente.</p>
</blockquote>
<hr />
<h2 id="interpretacion-del-enunciado">Interpretaci贸n del enunciado</h2>
<p>Dado que la matriz <span class="arithmatex">\(A\)</span> es de dimensiones <span class="arithmatex">\(n \times 2\)</span>, su descomposici贸n SVD <span class="arithmatex">\(A = U \Sigma V^t\)</span> nos indica rigurosamente, por propiedades algebraicas de dimensi贸n, que:</p>
<ul>
<li>
<p><span class="arithmatex">\(U\)</span> es una matriz ortogonal de <span class="arithmatex">\(n \times n\)</span>, por ende sus vectores columna la componen como <span class="arithmatex">\(U = [u_1, u_2, \dots, u_n]\)</span>.</p>
</li>
<li>
<p><span class="arithmatex">\(V\)</span> es una matriz ortogonal de <span class="arithmatex">\(2 \times 2\)</span>, ergo se compone acotadamente como <span class="arithmatex">\(V = [v_1, v_2]\)</span>.</p>
</li>
<li>
<p><span class="arithmatex">\(\Sigma\)</span> es una matriz de <span class="arithmatex">\(n \times 2\)</span> (mismas dimensiones que <span class="arithmatex">\(A\)</span>) que alberga a los valores singulares <span class="arithmatex">\(\sigma_i\)</span> estrictamente a lo largo de su "diagonal principal" (donde el 铆ndice de fila coincide con el de columna, <span class="arithmatex">\(\Sigma_{ii}\)</span>). <strong>En consecuencia, todos los dem谩s elementos que no pertenecen a esta diagonal son estrictamente nulos (<span class="arithmatex">\(\Sigma_{ij} = 0\)</span> para todo <span class="arithmatex">\(i \neq j\)</span>)</strong>. Esta es una propiedad basal inquebrantable de la SVD. A la hora de iterar, notamos que todas las filas contenidas entre <span class="arithmatex">\(n=3\)</span> hasta la 煤ltima (<span class="arithmatex">\(n\)</span>) ser谩n filas llenas enteramente de ceros.</p>
</li>
<li>
<p>La expresi贸n <span class="arithmatex">\(\tilde{A} = \sigma_1 u_1 v_1^t\)</span> se denomina <strong>aproximaci贸n de rango 1</strong>. El <strong>Teorema de Eckart-Young-Mirsky</strong> (<a href="https://es.wikipedia.org/wiki/Teorema_de_Eckart-Young-Mirsky">fuente matem谩tica</a>) en 谩lgebra lineal demuestra infaliblemente que al truncar la SVD reteniendo 煤nicamente el o los mayores valores singulares, se obtiene la matriz "m谩s cercana" posible a la original minimizando el margen de error, en el sentido de la Norma Rectangular Espectral (Norma-2) y de Frobenius. Por ende, la conjunci贸n de los mayores vectores singulares <span class="arithmatex">\(\sigma_1 u_1 v_1^t\)</span> conforma la proyecci贸n hiper-dimensional estricta de mayor asertividad para explicar la matriz general reduci茅ndola a un solo espectro principal (un solo vector-base).</p>
</li>
</ul>
<h2 id="solucion-inciso-a">Soluci贸n Inciso A</h2>
<blockquote>
<p>a) Si <span class="arithmatex">\(x \in \mathbb{R}^2\)</span> es un vector perteneciente al c铆rculo unitario, mostrar que el error cometido al calcular <span class="arithmatex">\(Ax\)</span> como <span class="arithmatex">\(\tilde{A}x\)</span> est谩 acotado por <span class="arithmatex">\(\sigma_2\)</span>.</p>
</blockquote>
<p>Sabemos por definici贸n de la SVD truncada que como la matriz original <span class="arithmatex">\(A\)</span> es de orden <span class="arithmatex">\(n \times 2\)</span>, s贸lo poseer谩 a lo sumo 2 valores singulares no nulos. Podemos entonces descomponerla como la suma de sus componentes de rango 1:</p>
<div class="arithmatex">\[A = \sum_{i=1}^{k} \sigma_i u_i v_i^t = \sigma_1 u_1 v_1^t + \sigma_2 u_2 v_2^t\]</div>
<details class="info">
<summary>Profundizaci贸n: Descomposici贸n en Sumatoria de Matrices de Rango 1</summary>
<p>Para cualquier matriz general <span class="arithmatex">\(M \in \mathbb{R}^{m \times n}\)</span> con rango <span class="arithmatex">\(r\)</span>, la Descomposici贸n en Valores Singulares <span class="arithmatex">\(M = U \Sigma V^t\)</span> puede ser reescrita l贸gicamente usando multiplicaci贸n por bloques como una sumatoria exacta de <span class="arithmatex">\(r\)</span> matrices individuales, cada una de rango estrictamente 1:</p>
<div class="arithmatex">\[M = \sum_{i=1}^{r} \sigma_i u_i v_i^t\]</div>
<p>Teniendo en cuenta que <span class="arithmatex">\(u_i\)</span> y <span class="arithmatex">\(v_i\)</span> son vectores columna, cada t茅rmino individual <span class="arithmatex">\(u_i v_i^t\)</span> (el <strong>producto exterior</strong> u <em>outer product</em> entre el <span class="arithmatex">\(i\)</span>-茅simo vector singular izquierdo y su equivalente derecho interpuesto) arroja una matriz bidimensional completa de <span class="arithmatex">\(m \times n\)</span>, pero de riguroso <strong>rango 1</strong> (al ser la multiplicaci贸n cruzada de meras vectores columnas lineales, todas las columnas de la matriz resultante terminan siendo m煤ltiplos de una 煤nica columna <span class="arithmatex">\(u_i\)</span>).</p>
<p>Al escalarla individualmente por su respectivo valor singular <span class="arithmatex">\(\sigma_i\)</span> (que act煤a como el "peso" escalado o la magnificaci贸n de esa componente a nivel espectral), la suma de estas "capas" de rango 1 superpuestas reconstruye milim茅tricamente la integralidad de <span class="arithmatex">\(M\)</span>, ponderando y priorizando los elementos de mayor dominancia (las direcciones singulares principales).</p>
<p> <em>Para verificar visualmente la demostraci贸n matem谩tica en pizarra impartida desde cero, pod茅s mirar la <a href="https://www.youtube.com/watch?v=mBcLRGuAFUk">Clase 29 (Singular Value Decomposition) dictada por Gilbert Strang para MIT 18.06 OpenCourseWare</a>.</em></p>
</details>
<p>Dado que se nos informa que <span class="arithmatex">\(\tilde{A} = \sigma_1 u_1 v_1^t\)</span> es la aproximaci贸n de mayor rango, podemos definir el error vectorial de efectuar dicha predicci贸n como <span class="arithmatex">\(e = A x - \tilde{A} x\)</span>.</p>
<p>Reemplazando los t茅rminos, el residuo es exactamente la componente descartada de la matriz SVD:</p>
<div class="arithmatex">\[e = (A - \tilde{A}) x = (\sigma_2 u_2 v_2^t) x\]</div>
<p>Nos piden probar que la norma de este error se encuentra acotada por <span class="arithmatex">\(\sigma_2\)</span>. Aplicamos la norma euclidiana o Norma-2 (<span class="arithmatex">\(|| \cdot ||_2\)</span>) en ambos lados:</p>
<div class="arithmatex">\[||e||_2 = ||\sigma_2 u_2 v_2^t x||_2\]</div>
<p>Como un escalar positivo puede extraerse de la norma:</p>
<details class="info">
<summary>Observaci贸n Te贸rica: 驴Por qu茅 <span class="arithmatex">\(\sigma_2\)</span> es un escalar puramente positivo?</summary>
<p>Por definici贸n intr铆nseca de la descomposici贸n SVD, todos los valores singulares escalares <span class="arithmatex">\(\sigma_i\)</span> que componen a <span class="arithmatex">\(\Sigma\)</span> son siempre n煤meros reales <strong>no negativos (<span class="arithmatex">\(\sigma_i \geq 0\)</span>)</strong>. Matem谩ticamente, esto deviene de que los valores <span class="arithmatex">\(\sigma\)</span> se calculan extrayendo la ra铆z cuadrada de los autovalores algebraicos de la matriz gramiana <span class="arithmatex">\(A^tA\)</span>.</p>
<p>Toda matriz pre-multiplicada por su transpuesta (<span class="arithmatex">\(A^tA\)</span>) genera autom谩ticamente una matriz sim茅trica semi-definida positiva. Las matrices de este tipo subyacen inevitablemente a un espectro limitante de autovalores reales y positivos (<span class="arithmatex">\(\lambda_i \geq 0\)</span>), imposibilitando en la abstracci贸n la existencia de ra铆ces imaginarias o valores singulares que fuesen negativos.</p>
<p>Adicionalmente, como el enunciado aclara que los valores singulares no admiten repetici贸n (<span class="arithmatex">\(\sigma_i \neq \sigma_j\)</span>) y provienen del habitual ordenamiento secular de magnitud descendente <span class="arithmatex">\(\sigma_1 &gt; \sigma_2 &gt; 0\)</span>, concluimos fehacientemente que <strong><span class="arithmatex">\(\sigma_2 &gt; 0\)</span></strong>. </p>
<p>Al refrendar que es un escalar puramente positivo para todo escenario, nuestra expresi贸n queda habilitada l铆citamente para desacoplar a <span class="arithmatex">\(\sigma_2\)</span> por fuera de la funci贸n valor absoluto de la norma m茅trica subyacente de la que era parte impunemente: <span class="arithmatex">\(|\sigma_2| = \sigma_2\)</span> y <span class="arithmatex">\(||\sigma_2 u|| = \sigma_2 ||u||\)</span>.</p>
<p> <em>Para consultar la probanza algebraica oficial de estas propiedades imperativas, pod茅s remitirte a la <a href="https://www.youtube.com/watch?v=vF7eyJ2g3kU">Clase 27 (Positive Definite Matrices and Minima) dictada por Gilbert Strang para MIT 18.06 OpenCourseWare</a>.</em></p>
</details>
<div class="arithmatex">\[||e||_2 = \sigma_2 ||u_2 (v_2^t x)||_2\]</div>
<p>El t茅rmino entre par茅ntesis <span class="arithmatex">\((v_2^t x)\)</span> resulta en un n煤mero escalar del producto interno vectorial. Lo podemos extraer en valor absoluto:</p>
<div class="arithmatex">\[||e||_2 = \sigma_2 |v_2^t x| \cdot ||u_2||_2\]</div>
<p>Dado que las matrices de la SVD componen isometr铆as ortogonales perfectas, <span class="arithmatex">\(U\)</span> y <span class="arithmatex">\(V\)</span> se componen de vectores columna ortonormales unitarios. Es una certeza, por ende, que el vector singular de la izquierda <span class="arithmatex">\(u_2\)</span> posee norma estricta igual a 1 (<span class="arithmatex">\(||u_2||_2 = 1\)</span>):</p>
<div class="arithmatex">\[||e||_2 = \sigma_2 |v_2^t x|\]</div>
<p>Al observar minuciosamente la parte restante correspondiente al producto interno <span class="arithmatex">\(|v_2^t x|\)</span>, descubrimos que ambos vectores provienen del disco estandarizado: sabemos que <span class="arithmatex">\(x \in \mathbb{R}^2\)</span> con <span class="arithmatex">\(||x||_2 = 1\)</span> (nos dicen que pertenece al "c铆rculo unitario") y paralelamente <span class="arithmatex">\(v_2\)</span> siempre es un vector ortonormal de <span class="arithmatex">\(V\)</span>, por lo cual <span class="arithmatex">\(||v_2||_2 = 1\)</span>.</p>
<p>Recurriendo a la c茅lebre inecuaci贸n de Cauchy-Schwarz:</p>
<div class="arithmatex">\[|v_2^t x| \leq ||v_2||_2 \cdot ||x||_2 = 1 \cdot 1 = 1\]</div>
<p>Consumiendo nuestra afirmaci贸n, arribamos a que:</p>
<div class="arithmatex">\[||e||_2 \leq \sigma_2 \cdot 1 = \sigma_2\]</div>
<p>Queda as铆 demostrado que el error cometido en la aproximaci贸n <span class="arithmatex">\(\|A x - \tilde{A} x\|_2\)</span> siempre estar谩 acotado por arriba por la magnitud del segundo valor singular descartado, <span class="arithmatex">\(\sigma_2\)</span>.</p>
<hr />
<h2 id="solucion-inciso-b">Soluci贸n Inciso B</h2>
<blockquote>
<p>b) Sea <span class="arithmatex">\(B = A^tA\)</span> y <span class="arithmatex">\(x \in \mathbb{R}^2\)</span> elegido al azar. Mostrar que el siguiente algoritmo converge al vector <span class="arithmatex">\(v_1\)</span> cuando <span class="arithmatex">\(N \to \infty\)</span>:</p>
<ul>
<li>
<p>Para <span class="arithmatex">\(k \in 1, \dots, N\)</span>:</p>
</li>
<li>
<p><span class="arithmatex">\(x = Bx\)</span></p>
</li>
<li>
<p><span class="arithmatex">\(x = x / ||x||\)</span></p>
</li>
</ul>
</blockquote>
<p>Si <span class="arithmatex">\(A = U \Sigma V^t\)</span>, podemos sustituirlo en lo provisto por la letra del ejercicio <span class="arithmatex">\(B = A^t A\)</span>:</p>
<div class="arithmatex">\[B = (U \Sigma V^t)^t (U \Sigma V^t) = V \Sigma^t U^t U \Sigma V^t\]</div>
<p>Dada la ortogonalidad de la matriz <span class="arithmatex">\(U\)</span>, sabemos que su autotranspuesta obedece <span class="arithmatex">\(U^t U = I\)</span>. Aplicando este axioma simplificador:</p>
<div class="arithmatex">\[B = V \Sigma^t \Sigma V^t\]</div>
<p>Dado que la matriz pre-multiplicada <span class="arithmatex">\(\Sigma^t \Sigma\)</span> conforma invariablemente una matriz diagonal cuadrada en la que surgen iterativamente los valores singulares originales elevados al cuadrado (<span class="arithmatex">\(\Sigma_{ii}^2 = \sigma_i^2\)</span>), entonces los autovalores formales de <span class="arithmatex">\(B\)</span> (que recordemos es de <span class="arithmatex">\(2 \times 2\)</span>), llamados convencionalmente <span class="arithmatex">\(\lambda_1\)</span> y <span class="arithmatex">\(\lambda_2\)</span>, son por a帽adidura:</p>
<div class="arithmatex">\[\lambda_1 = \sigma_1^2\]</div>
<div class="arithmatex">\[\lambda_2 = \sigma_2^2\]</div>
<p>Los autovectores de <span class="arithmatex">\(B\)</span> son precisamente las columnas de la matriz <span class="arithmatex">\(V\)</span>, denotados como <span class="arithmatex">\(v_1\)</span> y <span class="arithmatex">\(v_2\)</span>.</p>
<details class="info">
<summary>Observaci贸n Te贸rica: 驴Por qu茅 los autovectores de <span class="arithmatex">\(B\)</span> son las columnas de <span class="arithmatex">\(V\)</span>?</summary>
<p>A partir de la ecuaci贸n superior deducimos que <span class="arithmatex">\(B = V (\Sigma^t \Sigma) V^t\)</span>. Si a la matriz diagonal central la rebautizamos como <span class="arithmatex">\(\Lambda = \Sigma^t \Sigma\)</span>, nos queda formulado:</p>
<div class="arithmatex">\[B = V \Lambda V^t\]</div>
<p>Por definici贸n de la SVD, sabemos que <span class="arithmatex">\(V\)</span> conforma una matriz <strong>ortogonal</strong> perfecta. Las matrices ortogonales gozan de la propiedad inversa elemental en la que <span class="arithmatex">\(V^t = V^{-1}\)</span>. Sustituyendo esto en la ecuaci贸n:</p>
<div class="arithmatex">\[B = V \Lambda V^{-1}\]</div>
<p>Esta gloriosa disposici贸n coincide sim茅tricamente con la definici贸n can贸nica universal de la <strong>Diagonalizaci贸n de Matrices por Autovalores</strong> (<span class="arithmatex">\(M = P D P^{-1}\)</span>), donde el teorema espectral dicta irrefutablemente que <span class="arithmatex">\(D\)</span> (nuestra <span class="arithmatex">\(\Lambda\)</span>) es la matriz diagonal que aloja de forma descendente los <strong>autovalores</strong>, y <span class="arithmatex">\(P\)</span> (nuestra <span class="arithmatex">\(V\)</span>) es la matriz de paso cuyas columnas albergan los <strong>autovectores</strong> ortonormalizados linealmente independientes correspondientes a cada escal贸n de <span class="arithmatex">\(\Lambda\)</span>.</p>
<p>Por alineaci贸n axiom谩tica directa, las columnas de <span class="arithmatex">\(V\)</span> (<span class="arithmatex">\(v_1, v_2\)</span>) son sin lugar a dudas los autovectores de la matriz sim茅trica <span class="arithmatex">\(B\)</span>.</p>
<p> <em>Para verificar visualmente la demostraci贸n completa del Teorema Espectral y el mecanismo de diagonalizaci贸n <span class="arithmatex">\(\Lambda\)</span>, te sugiero consultar la <a href="https://www.youtube.com/watch?v=13r9QY6cmjc">Clase 22 (Diagonalization and Powers of A) dictada por Gilbert Strang para MIT 18.06 OpenCourseWare</a>.</em></p>
</details>
<p>En base a esto, y conociendo que los valores singulares de SVD exigen que <span class="arithmatex">\(\sigma_i \neq \sigma_j\)</span> y vienen t铆picamente ordenados descendiendo <span class="arithmatex">\(\sigma_1 &gt; \sigma_2 &gt; 0\)</span>, deducimos que <span class="arithmatex">\(\lambda_1 &gt; \lambda_2 \geq 0\)</span>.</p>
<details class="info">
<summary>Observaci贸n Te贸rica: 驴El orden estricto <span class="arithmatex">\(\sigma_1 &gt; \sigma_2 &gt; 0\)</span> es una convenci贸n algor铆tmica?</summary>
<p>S铆, la suposici贸n de que los valores <span class="arithmatex">\(\sigma\)</span> yacen ordenados algebraicamente de mayor a menor magnitud (<span class="arithmatex">\(\sigma_1 \ge \sigma_2 \ge \dots\)</span>) es la <strong>convenci贸n universal est谩ndar</strong> en todas las bibliotecas de c贸mputo inform谩tico (numpy, scipy) y en la formulaci贸n primigenia de la Descomposici贸n SVD.</p>
<p>La SVD est谩 dise帽ada axiom谩ticamente para reordenar las proyecciones de modo que el primer valor <span class="arithmatex">\(\sigma_1\)</span> sea siempre el componente supremo, englobando la direcci贸n de m谩xima varianza (o energ铆a matricial principal).</p>
<p>En el contexto estricto de nuestro ejercicio, el enunciado nos decreta preventivamente que <strong><span class="arithmatex">\(\sigma_i \neq \sigma_j\)</span> si <span class="arithmatex">\(i \neq j\)</span></strong>. Esta condici贸n suplementaria impuesta por el autor anula la posibilidad de que surja multiplicidad en los valores (el caso degenerado donde <span class="arithmatex">\(\sigma_1 = \sigma_2\)</span>). </p>
<p>Por consiguiente, la fusi贸n natural de la <strong>convenci贸n descendente gen茅rica de la SVD</strong> <span class="arithmatex">\((\sigma_1 \ge \sigma_2 \ge \dots \ge 0)\)</span> intersectada con la <strong>restricci贸n estricta de desigualdad del examen</strong> <span class="arithmatex">\((\sigma_1 \neq \sigma_2)\)</span>, nos conduce fehacientemente y sin fisuras anal铆ticas a que la sucesi贸n es estrictamente decreciente: <strong><span class="arithmatex">\(\sigma_1 &gt; \sigma_2 &gt; 0\)</span></strong>.</p>
<p> <em>Para verificar la convenci贸n doctrinal y matem谩tica detr谩s del ordenamiento matricial descendente de la SVD, pod茅s consultar la <a href="https://en.wikipedia.org/wiki/Singular_value_decomposition">Wikipedia: Singular Value Decomposition (Statement of the theorem)</a>.</em></p>
</details>
<p>El algoritmo planteado eval煤a un simple bucle <span class="arithmatex">\(k \in 1, \dots, N\)</span> sobre la operaci贸n iterada:</p>
<div class="arithmatex">\[x^{(k)} = \frac{B x^{(k-1)}}{||B x^{(k-1)}||} = \frac{B^k x^{(0)}}{||B^k x^{(0)}||}\]</div>
<details class="info">
<summary>Observaci贸n Te贸rica: 驴Por qu茅 la iteraci贸n asume esta forma colapsada general?</summary>
<p>El mecanismo fundamental del <strong>M茅todo de la Potencia</strong> normalizado a menudo confunde porque en cada paso iterativo se divide por la norma entera del vector obtenido, pareciendo perder el hilo del vector primigenio <span class="arithmatex">\(x^{(0)}\)</span>. No obstante, podemos probar por inducci贸n que esto es un simple cambio de escala unidimensional:</p>
<ol>
<li>En el paso 1, multiplicamos e inyectamos la norma: <span class="arithmatex">\(x^{(1)} = \frac{B x^{(0)}}{||B x^{(0)}||}\)</span>.</li>
<li>En el paso 2, insertamos <span class="arithmatex">\(x^{(1)}\)</span>: <span class="arithmatex">\(x^{(2)} = \frac{B x^{(1)}}{||B x^{(1)}||} = \frac{B \left( \frac{B x^{(0)}}{||B x^{(0)}||} \right)}{||B \left( \frac{B x^{(0)}}{||B x^{(0)}||} \right)||}\)</span>.</li>
</ol>
<p>Dado que los denominadores son estrictamente escalares num茅ricos reales (<span class="arithmatex">\(c = ||B x^{(0)}||\)</span>), las propiedades de linealidad de normas y matrices nos permiten sacar los escalares afuera tanto del numerador matricial como de la norma del denominador (<span class="arithmatex">\(B(c v) = c B v\)</span> y <span class="arithmatex">\(||c v|| = |c| ||v||\)</span>). </p>
<p>Al sacarlo de ambos lados simult谩neamente, <strong>el escalar acumulativo del paso anterior se cancela exactamente a s铆 mismo en el cociente</strong>:</p>
<div class="arithmatex">\[x^{(2)} = \frac{\frac{1}{||B x^{(0)}||} \cdot B^2 x^{(0)}}{\frac{1}{||B x^{(0)}||} \cdot ||B^2 x^{(0)}||} = \frac{B^2 x^{(0)}}{||B^2 x^{(0)}||}\]</div>
<p>Efectuando este patr贸n colapsable iterativamente <span class="arithmatex">\(k\)</span> veces (todos los divisores escalares de los pasos intermedios nacen y mueren mutuamente cancelados por linealidad), arribamos a la inmaculada conclusi贸n de que sin importar cu谩ndo o cu谩ntas veces re-normalicemos el vector a magnitud 1 durante el bucle de For, la direcci贸n espacial que apunta <span class="arithmatex">\(x^{(k)}\)</span> proviene indefectiblemente de elevar emp铆ricamente a <span class="arithmatex">\(B\)</span> a la potencia <span class="arithmatex">\(k\)</span> desde el inicio (<span class="arithmatex">\(B^k x^{(0)}\)</span>) y dividir todo ese armatoste final por su propia norma universal (<span class="arithmatex">\(||B^k x^{(0)}||\)</span>) reci茅n al terminar.</p>
<p> <em>Para consultar la demostraci贸n inductiva detallada y su verificaci贸n emp铆rica en Python, pod茅s remitirte al <a href="../../../demostraciones/01_metodo_potencia/">M茅todo de la Potencia</a>.</em></p>
</details>
<p>Se nos explica que <span class="arithmatex">\(x \in \mathbb{R}^2\)</span> es elegido al azar, por lo que podemos representarlo en funci贸n de la base ortonormal completa del plano compuesto por <span class="arithmatex">\(v_1\)</span> y <span class="arithmatex">\(v_2\)</span>:</p>
<div class="arithmatex">\[x^{(0)} = c_1 v_1 + c_2 v_2\]</div>
<details class="info">
<summary>Observaci贸n Te贸rica: 驴Por qu茅 <span class="arithmatex">\(v_1\)</span> y <span class="arithmatex">\(v_2\)</span> forman una Base Ortonormal completa para <span class="arithmatex">\(\mathbb{R}^2\)</span>?</summary>
<p>En la descomposici贸n SVD original (<span class="arithmatex">\(A = U \Sigma V^t\)</span>), la matriz <span class="arithmatex">\(V\)</span> tiene dimensiones <span class="arithmatex">\(2 \times 2\)</span>. Por los teoremas angulares fundamentales de la SVD, sabemos inquebrantablemente que <span class="arithmatex">\(V\)</span> es una <strong>Matriz Ortogonal</strong> cuadrada.</p>
<p>Toda matriz ortogonal cuadrada posee un espectro de vectores columna que son, por rigor axiom谩tico, mutuamente ortogonales (su producto punto interno es cero consecutivo, <span class="arithmatex">\(v_1 \cdot v_2 = 0\)</span>) y de norma unitaria (<span class="arithmatex">\(||v_i||_2 = 1\)</span>).</p>
<p>El espacio vectorial <span class="arithmatex">\(\mathbb{R}^2\)</span> (el "plano") tiene por definici贸n dimensi贸n 2. Como <span class="arithmatex">\(v_1\)</span> y <span class="arithmatex">\(v_2\)</span> son 2 vectores linealmente independientes (atestado irrefutablemente por ser ortogonales entre s铆), constituyen un conjunto maximalmente extenso para este espacio dimensional. </p>
<p>Al tener la misma cantidad de vectores ortogonales que dimensiones tiene el espacio, se erigen autom谩ticamente como una <strong>Base Ortonormal Completa</strong>. Por lo tanto, cualquier vector misterioso extra铆do al azar de <span class="arithmatex">\(\mathbb{R}^2\)</span> (como nuestro <span class="arithmatex">\(x^{(0)}\)</span>), puede ser modelado sint谩ctica y perfectamente a trav茅s de una combinaci贸n lineal bi-factorial directa de esta suprema "br煤jula" param茅trica: <span class="arithmatex">\(x^{(0)} = c_1 v_1 + c_2 v_2\)</span>.</p>
</details>
<p>Aplicando el 谩lgebra del operador iterativo con iteraciones tendientes a <span class="arithmatex">\(\infty\)</span>:</p>
<div class="arithmatex">\[B^k x^{(0)} = c_1 \lambda_1^k v_1 + c_2 \lambda_2^k v_2\]</div>
<details class="info">
<summary>Observaci贸n Te贸rica: 驴C贸mo opera <span class="arithmatex">\(B^k\)</span> iterativamente sobre la base de autovectores?</summary>
<p>Cuando aplicamos la matriz <span class="arithmatex">\(B\)</span> sucesivas veces sobre el vector inicial, estamos efectuando la operaci贸n <span class="arithmatex">\(B^k x^{(0)}\)</span>.</p>
<p>Por las propiedades definitorias del problema de autovalores, sabemos que pre-multiplicar la matriz <span class="arithmatex">\(B\)</span> por cualquiera de sus autovectores (<span class="arithmatex">\(v_i\)</span>) da un resultado vectorial id茅ntico a simplemente multiplicar ese vector por su escalar asimilado (<span class="arithmatex">\(\lambda_i\)</span>). En otras palabras, la matriz se comporta como un n煤mero y solo genera un estiramiento unidimensional, sin rotarlo en el espacio: <span class="arithmatex">\(B v_i = \lambda_i v_i\)</span>.</p>
<p>Si imponemos esta transformaci贸n <span class="arithmatex">\(k\)</span> veces sucesivas ("potencias de la matriz"), los factores de escala escalatorios crecen naturalmente de manera exponencial: <span class="arithmatex">\(B^k v_i = \lambda_i^k v_i\)</span>.</p>
<p>Sustituyendo en esta expresi贸n nuestro vector original partido en componentes del plano:</p>
<div class="arithmatex">\[B^k x^{(0)} = B^k (c_1 v_1 + c_2 v_2)\]</div>
<p>Propagando la transformaci贸n de la matriz por distributiva matricial pura:</p>
<div class="arithmatex">\[B^k x^{(0)} = c_1 (B^k v_1) + c_2 (B^k v_2)\]</div>
<p>Sustituyendo la conducta matricial proyectada en las componentes individuales para desacoplarnos matem谩ticamente del producto matricial y transformarlo en escalares algebraicos:</p>
<div class="arithmatex">\[B^k x^{(0)} = c_1 \lambda_1^k v_1 + c_2 \lambda_2^k v_2\]</div>
<p> <em>El basamento doctrinario supremo para asimilar c贸mo una matriz iterativa se deconstruye y expande sus propios autovalores en el tiempo es ilustrado majestuosamente en la <a href="https://www.youtube.com/watch?v=13r9QY6cmjc">Clase 22 (Diagonalization and Powers of A) - MIT 18.06 Linear Algebra, Fall 2005 por Gilbert Strang</a>.</em></p>
</details>
<p>Factorizando para independizarnos del exponente del autovalor dominante:</p>
<div class="arithmatex">\[B^k x^{(0)} = \lambda_1^k \left( c_1 v_1 + c_2 \left( \frac{\lambda_2}{\lambda_1} \right)^k v_2 \right)\]</div>
<p>Dado que denotamos ex-ante que <span class="arithmatex">\(\lambda_1 &gt; \lambda_2\)</span>, la fracci贸n es decididamente un n煤mero en el recuadro menor a la unidad <span class="arithmatex">\(( \frac{\lambda_2}{\lambda_1} &lt; 1 )\)</span>. Por propiedad de los l铆mites asint贸ticos exponenciales:</p>
<div class="arithmatex">\[\lim_{k \to \infty} \left( \frac{\lambda_2}{\lambda_1} \right)^k = 0\]</div>
<p>Al aproximarse velozmente todo el segundo t茅rmino aditivo al valor cero, obtenemos con precisi贸n que la iteraci贸n de nuestro vector de partida se alinear谩 siendo puramente colineal con el primer autovector:</p>
<div class="arithmatex">\[B^k x^{(0)} \approx \left( \lambda_1^k \cdot c_1 \right) v_1\]</div>
<p>Evidentemente si nuestro vector estoc谩stico naci贸 sin componente principal (<span class="arithmatex">\(c_1 = 0\)</span>, ortogonalidad perfecta elegida para nuestra semilla inicial), el proceso fallar谩 al converger a <span class="arithmatex">\(v_2\)</span>.</p>
<details class="info">
<summary>Observaci贸n Te贸rica: 驴Qu茅 ocurre matem谩ticamente si <span class="arithmatex">\(c_1 = 0\)</span>? 驴El vector se vuelve nulo?</summary>
<p>Al notar que <span class="arithmatex">\(\left( \frac{\lambda_2}{\lambda_1} \right)^k \to 0\)</span>, es tentador intuir que si <span class="arithmatex">\(c_1 = 0\)</span> todo el conjunto colapsar谩 hacia el vector <span class="arithmatex">\((0,0)\)</span>. No obstante, la factorizaci贸n matem谩tica extrayendo un factor com煤n de <span class="arithmatex">\(\lambda_1^k\)</span> se dise帽a y aporta valor 煤nicamente para analizar el l铆mite cuando ambas componentes coexisten (<span class="arithmatex">\(c_1 \neq 0\)</span>).</p>
<p>Si verdaderamente tuvi茅semos asilamiento puro de <span class="arithmatex">\(c_1 = 0\)</span>, debemos analizar la sumatoria original intacta:</p>
<div class="arithmatex">\[B^k x^{(0)} = 0 \cdot \lambda_1^k v_1 + c_2 \lambda_2^k v_2 = c_2 \lambda_2^k v_2\]</div>
<p>Dado que en el M茅todo de la Potencia el paso es normalizar forzosamente <span class="arithmatex">\(x^{(k)} = \frac{B^k x^{(0)}}{||B^k x^{(0)}||}\)</span>, no importa cu谩n microsc贸pico se torne el escalar <span class="arithmatex">\(\lambda_2^k \to 0\)</span> con el avance del tiempo, al estar en el numerador y denominador sometido bajo norma <strong>茅ste se cancela intr铆nsecamente</strong>:</p>
<div class="arithmatex">\[x^{(k)} = \frac{c_2 \lambda_2^k v_2}{||c_2 \lambda_2^k v_2||} = \frac{c_2 \lambda_2^k}{|c_2| \lambda_2^k} \cdot \frac{v_2}{||v_2||} = \text{sgn}(c_2) v_2\]</div>
<p>Por consiguiente, el algoritmo <strong>jam谩s tender谩 al origen <span class="arithmatex">\((0,0)\)</span></strong>; la normalizaci贸n iterativa act煤a como un ant铆doto perpetuo que estirar谩 de vuelta a cualquier remanente hacia el c铆rculo unitario (norma 1), quedando estacionado inamoviblemente en <span class="arithmatex">\(\pm v_2\)</span>.</p>
</details>
<p>Tal salvedad, en algoritmos estoc谩sticos que operan en floats (cuyos conjuntos de medida afirman que extraer el exacto plano euclidiano ortogonal de <span class="arithmatex">\(v_1\)</span> al azar tiene te贸ricamente "probabilidad cero"), carece de sustento para descalificar la iteraci贸n, ya que cualquier ruido de precisi贸n 铆nfimo garantiza que nazca un <span class="arithmatex">\(c_1 \neq 0\)</span> que indefectiblemente terminar谩 dominando el l铆mite asint贸tico.</p>
<p>Como para rematar cada ciclo el vector se normaliza contra s铆 mismo <span class="arithmatex">\(x = \frac{x}{||x||}\)</span>, todo componente escalar global <span class="arithmatex">\(\lambda\)</span> decae por divisiones intr铆nsecas, dejando con exclusividad un vector de tama帽o 1 alineado a la direcci贸n principal:</p>
<div class="arithmatex">\[\lim_{N \to \infty} x^{(N)} = \pm v_1\]</div>
<p>Evidenciando la validez asint贸tica te贸rica de lo que universalmente nombramos "M茅todo de la Potencia".</p>
<hr />
<h2 id="solucion-inciso-c-rutina-en-python">Soluci贸n Inciso C: Rutina en Python</h2>
<blockquote>
<p>c) Escriba una rutina que calcule la mejor aproximaci贸n de rango 1 de una matriz real de <span class="arithmatex">\(n \times 2\)</span> en el sentido de la norma 2. Toda funci贸n que involucre operaciones m谩s complejas que el producto matricial debe ser definida expl铆citamente.</p>
</blockquote>
<p>A continuaci贸n, la rutina desarrollada sin emplear funciones de grado superlativo como factorizaciones directas en la librer铆a algor铆tmica. Para hallar el valor singular predominante nos basamos en el cociente de Rayleigh, aplicando producto punto cl谩sico entre la iteraci贸n convergiendo de las potencias.</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="k">def</span><span class="w"> </span><span class="nf">run_tests</span><span class="p">():</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- Verificaci贸n Inciso A ---&quot;</span><span class="p">)</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>  <span class="c1"># Para la consistencia l贸gica de todo el script</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="n">n</span> <span class="o">=</span> <span class="mi">5</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">Vt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="n">sigma_1</span><span class="p">,</span> <span class="n">sigma_2</span> <span class="o">=</span> <span class="n">S</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">S</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="c1"># Construcci贸n referencial de la aproximaci贸n de rango 1</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="n">u1</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="n">v1</span> <span class="o">=</span> <span class="n">Vt</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    <span class="n">A_tilde</span> <span class="o">=</span> <span class="n">sigma_1</span> <span class="o">*</span> <span class="p">(</span><span class="n">u1</span> <span class="o">@</span> <span class="n">v1</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="c1"># Simular vector aleatorio unitario probabil铆stico (C铆rculo Unitario)</span>
</span><span id="__span-0-17"><a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
</span><span id="__span-0-18"><a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)],</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)]])</span>
</span><span id="__span-0-19"><a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>
</span><span id="__span-0-20"><a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>    <span class="c1"># Efectuar la predicci贸n restada a la original para hallar residuo</span>
</span><span id="__span-0-21"><a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>    <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span> <span class="o">@</span> <span class="n">x</span> <span class="o">-</span> <span class="n">A_tilde</span> <span class="o">@</span> <span class="n">x</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="__span-0-22"><a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error calculado euclidiamente ||Ax - A_tilda x||_2:</span><span class="se">\t</span><span class="s2"> </span><span class="si">{</span><span class="n">error</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-0-23"><a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cota superior l铆mite exigida anal铆ticamente (sigma_2):</span><span class="se">\t</span><span class="s2"> </span><span class="si">{</span><span class="n">sigma_2</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-0-24"><a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;驴Atiende la aserci贸n te贸rica? (Error &lt;= sigma_2):</span><span class="se">\t</span><span class="s2"> </span><span class="si">{</span><span class="n">error</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">sigma_2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-0-25"><a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>
</span><span id="__span-0-26"><a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>
</span><span id="__span-0-27"><a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Verificaci贸n Inciso B y Soluci贸n Emp铆rica Inciso C ---&quot;</span><span class="p">)</span>
</span><span id="__span-0-28"><a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>
</span><span id="__span-0-29"><a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>    <span class="n">B</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">A</span>
</span><span id="__span-0-30"><a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>
</span><span id="__span-0-31"><a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>    <span class="c1"># Rutina iterativa solicitada en el inciso C, donde la norma expl铆cita no puede usar linalg.norm</span>
</span><span id="__span-0-32"><a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">best_rank_1_approximation</span><span class="p">(</span><span class="n">mat_A</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
</span><span id="__span-0-33"><a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-34"><a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a><span class="sd">        Rutina puramente axiom谩tica fundamentada en matrices elementales sin svd.</span>
</span><span id="__span-0-35"><a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a><span class="sd">        Halla la aproximaci贸n computacional limit谩ndose al producto de matrices algebraico y potencias.</span>
</span><span id="__span-0-36"><a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="__span-0-37"><a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>        <span class="n">mat_B</span> <span class="o">=</span> <span class="n">mat_A</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">mat_A</span>
</span><span id="__span-0-38"><a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>
</span><span id="__span-0-39"><a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>        <span class="c1"># Iniciaci贸n del vector aleatorio x (Inciso B)</span>
</span><span id="__span-0-40"><a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>        <span class="n">x_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-41"><a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>
</span><span id="__span-0-42"><a id="__codelineno-0-42" name="__codelineno-0-42" href="#__codelineno-0-42"></a>        <span class="c1"># Iteraci贸n asint贸tica (N -&gt; Infinito, para nosotros 100)</span>
</span><span id="__span-0-43"><a id="__codelineno-0-43" name="__codelineno-0-43" href="#__codelineno-0-43"></a>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
</span><span id="__span-0-44"><a id="__codelineno-0-44" name="__codelineno-0-44" href="#__codelineno-0-44"></a>            <span class="n">x_k</span> <span class="o">=</span> <span class="n">mat_B</span> <span class="o">@</span> <span class="n">x_k</span>
</span><span id="__span-0-45"><a id="__codelineno-0-45" name="__codelineno-0-45" href="#__codelineno-0-45"></a>
</span><span id="__span-0-46"><a id="__codelineno-0-46" name="__codelineno-0-46" href="#__codelineno-0-46"></a>            <span class="c1"># Normalizaci贸n manual a nivel matricial (x[0]^2 + x[1]^2)^0.5</span>
</span><span id="__span-0-47"><a id="__codelineno-0-47" name="__codelineno-0-47" href="#__codelineno-0-47"></a>            <span class="n">norm_xk</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_k</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x_k</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mf">0.5</span>
</span><span id="__span-0-48"><a id="__codelineno-0-48" name="__codelineno-0-48" href="#__codelineno-0-48"></a>            <span class="n">x_k</span> <span class="o">=</span> <span class="n">x_k</span> <span class="o">/</span> <span class="n">norm_xk</span>
</span><span id="__span-0-49"><a id="__codelineno-0-49" name="__codelineno-0-49" href="#__codelineno-0-49"></a>
</span><span id="__span-0-50"><a id="__codelineno-0-50" name="__codelineno-0-50" href="#__codelineno-0-50"></a>        <span class="n">v_1_approx</span> <span class="o">=</span> <span class="n">x_k</span>
</span><span id="__span-0-51"><a id="__codelineno-0-51" name="__codelineno-0-51" href="#__codelineno-0-51"></a>
</span><span id="__span-0-52"><a id="__codelineno-0-52" name="__codelineno-0-52" href="#__codelineno-0-52"></a>        <span class="c1"># Hallar Rayleigh quotient para aproximar lambda_1</span>
</span><span id="__span-0-53"><a id="__codelineno-0-53" name="__codelineno-0-53" href="#__codelineno-0-53"></a>        <span class="c1"># Lambda_1 = (v_1^T B v_1) / (v_1^T v_1) =&gt; al ser v_1 unitario, omitimos la divisi贸n.</span>
</span><span id="__span-0-54"><a id="__codelineno-0-54" name="__codelineno-0-54" href="#__codelineno-0-54"></a>        <span class="n">lambda_1</span> <span class="o">=</span> <span class="p">(</span><span class="n">v_1_approx</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">mat_B</span> <span class="o">@</span> <span class="n">v_1_approx</span><span class="p">))[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
</span><span id="__span-0-55"><a id="__codelineno-0-55" name="__codelineno-0-55" href="#__codelineno-0-55"></a>
</span><span id="__span-0-56"><a id="__codelineno-0-56" name="__codelineno-0-56" href="#__codelineno-0-56"></a>        <span class="c1"># Recuperar par谩metro principal sigma_1 como la ra铆z limitante est谩tica de la varianza espectral</span>
</span><span id="__span-0-57"><a id="__codelineno-0-57" name="__codelineno-0-57" href="#__codelineno-0-57"></a>        <span class="n">sigma_1_approx</span> <span class="o">=</span> <span class="n">lambda_1</span><span class="o">**</span><span class="mf">0.5</span>
</span><span id="__span-0-58"><a id="__codelineno-0-58" name="__codelineno-0-58" href="#__codelineno-0-58"></a>
</span><span id="__span-0-59"><a id="__codelineno-0-59" name="__codelineno-0-59" href="#__codelineno-0-59"></a>        <span class="c1"># Recobrar u_1 aislando el vector matricial en la relaci贸n (A v_1 = sigma_1 u_1)</span>
</span><span id="__span-0-60"><a id="__codelineno-0-60" name="__codelineno-0-60" href="#__codelineno-0-60"></a>        <span class="n">u_1_approx</span> <span class="o">=</span> <span class="p">(</span><span class="n">mat_A</span> <span class="o">@</span> <span class="n">v_1_approx</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">sigma_1_approx</span><span class="p">)</span>
</span><span id="__span-0-61"><a id="__codelineno-0-61" name="__codelineno-0-61" href="#__codelineno-0-61"></a>
</span><span id="__span-0-62"><a id="__codelineno-0-62" name="__codelineno-0-62" href="#__codelineno-0-62"></a>        <span class="c1"># Compilar y emparejar la expresi贸n final A_tilde</span>
</span><span id="__span-0-63"><a id="__codelineno-0-63" name="__codelineno-0-63" href="#__codelineno-0-63"></a>        <span class="n">A_tilde_approx</span> <span class="o">=</span> <span class="n">sigma_1_approx</span> <span class="o">*</span> <span class="p">(</span><span class="n">u_1_approx</span> <span class="o">@</span> <span class="n">v_1_approx</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</span><span id="__span-0-64"><a id="__codelineno-0-64" name="__codelineno-0-64" href="#__codelineno-0-64"></a>
</span><span id="__span-0-65"><a id="__codelineno-0-65" name="__codelineno-0-65" href="#__codelineno-0-65"></a>        <span class="k">return</span> <span class="n">A_tilde_approx</span><span class="p">,</span> <span class="n">v_1_approx</span>
</span><span id="__span-0-66"><a id="__codelineno-0-66" name="__codelineno-0-66" href="#__codelineno-0-66"></a>
</span><span id="__span-0-67"><a id="__codelineno-0-67" name="__codelineno-0-67" href="#__codelineno-0-67"></a>    <span class="n">A_tilde_approx</span><span class="p">,</span> <span class="n">v1_approx</span> <span class="o">=</span> <span class="n">best_rank_1_approximation</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
</span><span id="__span-0-68"><a id="__codelineno-0-68" name="__codelineno-0-68" href="#__codelineno-0-68"></a>
</span><span id="__span-0-69"><a id="__codelineno-0-69" name="__codelineno-0-69" href="#__codelineno-0-69"></a>    <span class="n">v1_true</span> <span class="o">=</span> <span class="n">Vt</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-70"><a id="__codelineno-0-70" name="__codelineno-0-70" href="#__codelineno-0-70"></a>    <span class="c1"># El producto interno entre dos vectores unitarios paralelos es 1 o -1</span>
</span><span id="__span-0-71"><a id="__codelineno-0-71" name="__codelineno-0-71" href="#__codelineno-0-71"></a>    <span class="n">dot_product</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">v1_approx</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">v1_true</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</span><span id="__span-0-72"><a id="__codelineno-0-72" name="__codelineno-0-72" href="#__codelineno-0-72"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Producto interno abs(v1_approx^T * v1_true):</span><span class="se">\t\t</span><span class="s2"> </span><span class="si">{</span><span class="n">dot_product</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2"> (Demuestra el l铆mite en Inciso B)&quot;</span><span class="p">)</span>
</span><span id="__span-0-73"><a id="__codelineno-0-73" name="__codelineno-0-73" href="#__codelineno-0-73"></a>
</span><span id="__span-0-74"><a id="__codelineno-0-74" name="__codelineno-0-74" href="#__codelineno-0-74"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Discrepancia Global entre Matrices A_tilde ---&quot;</span><span class="p">)</span>
</span><span id="__span-0-75"><a id="__codelineno-0-75" name="__codelineno-0-75" href="#__codelineno-0-75"></a>    <span class="n">divergencia_absoluta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">A_tilde</span> <span class="o">-</span> <span class="n">A_tilde_approx</span><span class="p">))</span>
</span><span id="__span-0-76"><a id="__codelineno-0-76" name="__codelineno-0-76" href="#__codelineno-0-76"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Desfase posicional absoluto entre nuestra Rutina y la SVD natural: </span><span class="si">{</span><span class="n">divergencia_absoluta</span><span class="si">:</span><span class="s2">.8e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-0-77"><a id="__codelineno-0-77" name="__codelineno-0-77" href="#__codelineno-0-77"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;驴Son matem谩ticamente equivalentes sin discrepancia del hardware? (np.allclose):&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">A_tilde</span><span class="p">,</span> <span class="n">A_tilde_approx</span><span class="p">))</span>
</span><span id="__span-0-78"><a id="__codelineno-0-78" name="__codelineno-0-78" href="#__codelineno-0-78"></a>
</span><span id="__span-0-79"><a id="__codelineno-0-79" name="__codelineno-0-79" href="#__codelineno-0-79"></a><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
</span><span id="__span-0-80"><a id="__codelineno-0-80" name="__codelineno-0-80" href="#__codelineno-0-80"></a>    <span class="n">run_tests</span><span class="p">()</span>
</span></code></pre></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../../..", "features": ["navigation.tabs", "navigation.sections", "navigation.expand", "content.code.copy", "content.code.annotate"], "search": "../../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>